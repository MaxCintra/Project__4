{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f20354",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726814b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (946932284.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 41\u001b[1;36m\u001b[0m\n\u001b[1;33m    merged_data_2012 = pd.merge(file1, file12, file23 on='Player', how='inner')\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in all csvs\n",
    "file1 = pd.read_csv('Data/2012c.csv')\n",
    "file2 = pd.read_csv('Data/2013c.csv')\n",
    "file3 = pd.read_csv('Data/2014c.csv')\n",
    "file4 = pd.read_csv('Data/2015c.csv')\n",
    "file5 = pd.read_csv('Data/2016c.csv')\n",
    "file6 = pd.read_csv('Data/2017c.csv')\n",
    "file7 = pd.read_csv('Data/2018c.csv')\n",
    "file8 = pd.read_csv('Data/2019c.csv')\n",
    "file9 = pd.read_csv('Data/2020c.csv')\n",
    "file10 = pd.read_csv('Data/2021c.csv')\n",
    "file11 = pd.read_csv('Data/2022c.csv')\n",
    "file12 = pd.read_csv('Data/2012x.csv')\n",
    "file13 = pd.read_csv('Data/2013x.csv')\n",
    "file14 = pd.read_csv('Data/2014x.csv')\n",
    "file15 = pd.read_csv('Data/2015x.csv')\n",
    "file16 = pd.read_csv('Data/2016x.csv')\n",
    "file17 = pd.read_csv('Data/2017x.csv')\n",
    "file18 = pd.read_csv('Data/2018x.csv')\n",
    "file19 = pd.read_csv('Data/2019x.csv')\n",
    "file20 = pd.read_csv('Data/2020x.csv')\n",
    "file21 = pd.read_csv('Data/2021x.csv')\n",
    "file22 = pd.read_csv('Data/2022x.csv')\n",
    "file23 = pd.read_csv('Data/2012t.csv')\n",
    "file24 = pd.read_csv('Data/2013t.csv')\n",
    "file25 = pd.read_csv('Data/2014t.csv')\n",
    "file26 = pd.read_csv('Data/2015t.csv')\n",
    "file27 = pd.read_csv('Data/2016t.csv')\n",
    "file28 = pd.read_csv('Data/2017t.csv')\n",
    "file29 = pd.read_csv('Data/2018t.csv')\n",
    "file30 = pd.read_csv('Data/2019t.csv')\n",
    "file31 = pd.read_csv('Data/2020t.csv')\n",
    "file32 = pd.read_csv('Data/2021t.csv')\n",
    "file33 = pd.read_csv('Data/2022t.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Merge two DataFrames for each year and merge based on the \"Player\" column\n",
    "merged_data_2012 = pd.merge(file1, file12, file23 on='Player', how='inner')\n",
    "merged_data_2013 = pd.merge(file2, file13, file24 on='Player', how='inner')\n",
    "merged_data_2014 = pd.merge(file3, file14, file25 on='Player', how='inner')\n",
    "merged_data_2015 = pd.merge(file4, file15, file26 on='Player', how='inner')\n",
    "merged_data_2016 = pd.merge(file5, file16, file27 on='Player', how='inner')\n",
    "merged_data_2017 = pd.merge(file6, file17, file28 on='Player', how='inner')\n",
    "merged_data_2018 = pd.merge(file7, file18, file29 on='Player', how='inner')\n",
    "merged_data_2019 = pd.merge(file8, file19, file30 on='Player', how='inner')\n",
    "merged_data_2020 = pd.merge(file9, file20, file31 on='Player', how='inner')\n",
    "merged_data_2021 = pd.merge(file10, file21, file32 on='Player', how='inner')\n",
    "merged_data_2022 = pd.merge(file11, file22, file33 on='Player', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_combined_data = pd.concat([merged_data_2012,\n",
    "merged_data_2013,\n",
    "merged_data_2014,\n",
    "merged_data_2015,\n",
    "merged_data_2016,\n",
    "merged_data_2017,\n",
    "merged_data_2018,\n",
    "merged_data_2019,\n",
    "merged_data_2020,\n",
    "merged_data_2021,\n",
    "merged_data_2022])\n",
    "\n",
    "# Save the master combined DataFrame as a CSV file\n",
    "master_combined_data.to_csv('Data/eleven_year_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065a02a",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/eleven_year_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AP1'] = df['AP1'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['PB'] = df['PB'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ccd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Feet', 'Inches']] = df['Ht'].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Feet'] = pd.to_numeric(df['Feet'])\n",
    "df['Inches'] = pd.to_numeric(df['Inches'])\n",
    "df['Ht'] = df['Feet'] * 12 + df['Inches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['-9999', 'Player-additional', 'Feet', 'Inches']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f838a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caea8ee",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca00986",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = df['Pos'].unique()\n",
    "\n",
    "# Iterate over each position group\n",
    "for pos in positions:\n",
    "    # Filter the data for the current position\n",
    "    pos_data = df[df['Pos'] == pos].copy()\n",
    "\n",
    "    # Calculate the mean for selected columns\n",
    "    mean_values = pos_data[['40yd', 'Vertical', 'Bench', 'Broad Jump', '3Cone', 'Shuttle']].mean()\n",
    "\n",
    "    # Impute missing values with mean values in the copy\n",
    "    pos_data[['40yd', 'Vertical', 'Bench', 'Broad Jump', '3Cone', 'Shuttle']] = pos_data[['40yd', 'Vertical', 'Bench', 'Broad Jump', '3Cone', 'Shuttle']].fillna(mean_values)\n",
    "\n",
    "    # Merge imputed data back into the original dataset\n",
    "    df.update(pos_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2029a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Pos'] != 'K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45262fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb1523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in 'Bench' with -9999 for positions that don't compete\n",
    "df['Bench'].fillna(15, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c866685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan = df.isna().any().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"There are NaN values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_locations = df[df.isna().any(axis=1)]\n",
    "\n",
    "# Print rows and columns with NaN values\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_locations)\n",
    "\n",
    "print(\"\\nColumns with NaN values:\")\n",
    "print(df.columns[df.isna().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6504202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan = df.isna().any().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"There are NaN values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_positions = df['Pos'].unique()\n",
    "print(unique_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1695efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_encoding = {\n",
    "    'QB': 1,\n",
    "    'RB': 2,\n",
    "    'T': 3,\n",
    "    'WR': 4,\n",
    "    'DB': 5,\n",
    "    'LB': 6,\n",
    "    'DT': 7,\n",
    "    'DE': 8,\n",
    "    'G': 9,\n",
    "    'TE': 10,\n",
    "    'C': 11,\n",
    "    'P': 12,\n",
    "    'OL': 13,\n",
    "    'NT': 14,\n",
    "    'FB': 15,\n",
    "    'OLB': 16,\n",
    "    'CB': 17,\n",
    "    'S': 18,\n",
    "    'ILB': 19,\n",
    "    'LS': 20,\n",
    "    'DL': 21,\n",
    "}\n",
    "df['Pos_encoded'] = df['Pos'].map(position_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81495dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e635cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_schools = df['College/Univ'].unique()\n",
    "print(unique_schools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673424bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_encoding = {}\n",
    "for i, school in enumerate(unique_schools):\n",
    "    school_encoding[school] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['College/Univ_encoded'] = df['College/Univ'].map(school_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa656342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##df.to_csv('final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81443b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
